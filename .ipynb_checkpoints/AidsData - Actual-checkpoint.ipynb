{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brown-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import sys\n",
    "from graphkitlearn.graphkitlearn.gklearn.utils import graphfiles\n",
    "import networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gklearn.utils import *\n",
    "import os\n",
    "import random\n",
    "from gklearn.ged.env import GEDEnv\n",
    "import numpy as np\n",
    "from time import process_time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import *\n",
    "import datetime\n",
    "pathAids = \"./AIDS/AIDS/data/\"\n",
    "path1Grec = \"./GREC/GREC/data/\"\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "military-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(filename, childrentagName):\n",
    "    import xml.etree.ElementTree as ET\n",
    "    dirname_dataset = os.path.dirname(filename)\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    data = []\n",
    "    y = []\n",
    "    children = list([elem for elem in root.find(childrentagName).iter() if elem is not root.find(childrentagName)])\n",
    "    for graph in children:\n",
    "        mol_filename = graph.attrib['file']\n",
    "        mol_class = graph.attrib['class']\n",
    "        data.append(graphfiles.loadGXL(dirname_dataset + '/' + mol_filename))\n",
    "        y.append(mol_class)\n",
    "    return data, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vertical-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphHelper:\n",
    "    def __init__(self, trainData, mProtoTypes):\n",
    "        self.trainData = trainData\n",
    "        self.InitializeGraphToVector(trainData, mProtoTypes)\n",
    "        self.mProtoTypes = mProtoTypes\n",
    "        \n",
    "    def GetDistanceBetweenGraphs(self,graph1, graph2):\n",
    "        ged_env = GEDEnv() # initailize GED environment.\n",
    "        ged_env.set_edit_cost('CONSTANT', # GED cost type.\n",
    "                            edit_cost_constants=[3, 3, 1, 3, 3, 1] # edit costs.\n",
    "                            )  \n",
    "        ged_env.add_nx_graph(graph1, '') # add graph1\n",
    "        ged_env.add_nx_graph(graph2, '') # add graph2\n",
    "        listID = ged_env.get_all_graph_ids() # get list IDs of graphs\n",
    "        ged_env.init(init_type='LAZY_WITHOUT_SHUFFLED_COPIES') # initialize GED environment.\n",
    "        options = {'initialization_method': 'RANDOM', # or 'NODE', etc.\n",
    "                'threads': 1 # parallel threads.\n",
    "                }\n",
    "        ged_env.set_method('BIPARTITE', # GED method.\n",
    "                        options # options for GED method.\n",
    "                        )\n",
    "        ged_env.init_method() # initialize GED method.\n",
    "\n",
    "        ged_env.run_method(listID[0], listID[1]) # run.\n",
    "        dis = ged_env.get_upper_bound(listID[0], listID[1])\n",
    "        return dis\n",
    "\n",
    "    def MaxEditDistance(self, graphSets, nodes, addedIndices):\n",
    "        distanceVector = np.empty(shape=(len(graphSets ), len(nodes)))\n",
    "        for graphIndex,graph in enumerate(graphSets):\n",
    "            for nodeIndex,node in enumerate(nodes):\n",
    "                dis = self.GetDistanceBetweenGraphs(graph, node)\n",
    "                distanceVector[graphIndex][nodeIndex] = dis\n",
    "        maxValue = -1\n",
    "        maxIndex = -1\n",
    "        for graphIndex in range(len(graphSets)):\n",
    "            if(graphIndex not in addedIndices):\n",
    "                maxDistanceIndex = np.argmax(distanceVector[graphIndex])\n",
    "                if(distanceVector[graphIndex][maxDistanceIndex] > maxValue):\n",
    "                    maxValue = distanceVector[graphIndex][maxDistanceIndex]\n",
    "                    maxIndex = graphIndex\n",
    "\n",
    "        return maxIndex\n",
    "\n",
    "    def SelectSpanningPrototypes(self, graphData, mprototypes):\n",
    "        choiceIndex = random.randrange(len(graphData))\n",
    "        graphSelected = [graphData[choiceIndex]]\n",
    "        graphSelectedIndex = [choiceIndex]\n",
    "\n",
    "        for selectors in range(mprototypes - 1):\n",
    "            maxEditDistanceIndex = self.MaxEditDistance(graphData, graphSelected, graphSelectedIndex)\n",
    "            graphSelectedIndex.append(maxEditDistanceIndex)\n",
    "            graphSelected.append(graphData[maxEditDistanceIndex])\n",
    "        return graphSelectedIndex\n",
    "    \n",
    "    def GraphToVector(self, graphSet):\n",
    "        vectorMatrix = np.empty(shape= (len(graphSet), self.mProtoTypes))\n",
    "        for row, graph in enumerate(graphSet):\n",
    "            for col,prototypeIndex in enumerate(self.selectedProtoTypes):\n",
    "                vectorMatrix[row][col] = self.GetDistanceBetweenGraphs(graph, self.trainData[prototypeIndex])\n",
    "        return vectorMatrix\n",
    "    \n",
    "    def InitializeGraphToVector(self, graphSet, mprotoTypes):\n",
    "        self.selectedProtoTypes = self.SelectSpanningPrototypes(graphSet, mprotoTypes)\n",
    "        #return self.GraphToVector(graphSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "matched-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainAids, y_train = LoadData(pathAids +\"train.cxl\", \"fingerprints\")\n",
    "XvalidateAids, y_validate = LoadData(pathAids +\"valid.cxl\", \"fingerprints\")\n",
    "XtestAids, y_test = LoadData(pathAids +\"test.cxl\", \"fingerprints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dental-still",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853.046875\n",
      "Completed Prototype Selection at  2021-04-24 13:18:20.758335\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "graph = GraphHelper(XtrainAids, 10)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Prototype Selection at \", str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hungarian-series",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171.171875\n",
      "Completed Train Conversion at  2021-04-24 13:21:13.061440\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "trainVector = graph.GraphToVector(XtrainAids)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Train Conversion at \", str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amino-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034.9375\n",
      "Completed Test at  2021-04-24 13:38:34.677509\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "testVector = graph.GraphToVector(XtestAids)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Test at \", str(now))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southwest-pillow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.8125\n",
      "Completed Validation at  2021-04-24 13:41:28.737996\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "validationVector = graph.GraphToVector(XvalidateAids)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Validation at \", str(now))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-assurance",
   "metadata": {},
   "source": [
    "## Saving the computed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "electoral-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"TrainVectorAids\", trainVector)\n",
    "np.save(\"TestVectorAids\", testVector)\n",
    "np.save(\"validateVectorAids\", validationVector)\n",
    "with open('GraphHelperObjAids', 'wb') as config_dictionary_file:\n",
    "    pickle.dump(graph, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-france",
   "metadata": {},
   "source": [
    "## Loading from saved files \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "false-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVector = np.load(\"TrainVectorAids.npy\")\n",
    "testVector = np.load(\"TestVectorAids.npy\")\n",
    "validationVector = np.load(\"validateVectorAids.npy\")\n",
    "with open('GraphHelperObjAids', 'rb') as config_dictionary_file:\n",
    "    graph = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "documentary-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "def get_intra_cluster_distance(cluster_centroids,train_data_labels, trainVector) :\n",
    "    \n",
    "    number_of_clusters = cluster_centroids.shape[0]\n",
    "    \n",
    "    dist_list = []\n",
    "    for i in range(number_of_clusters) :\n",
    "        dist_list.append(0)\n",
    "    \n",
    "    for i in range(trainVector.shape[0]) :\n",
    "        \n",
    "        cluster_number = train_data_labels[i]\n",
    "        eucl_dist = cluster_centroids[cluster_number] - trainVector[i]\n",
    "        eucl_dist = np.square(eucl_dist)\n",
    "        eucl_dist = np.sum(eucl_dist)\n",
    "        eucl_dist = math.sqrt(eucl_dist)\n",
    "        \n",
    "        dist_list[cluster_number] = dist_list[cluster_number] + eucl_dist\n",
    "    #for i in range(number_of_clusters) :\n",
    "    #    dist_list[i] /= np.where(train_data_labels == i)[0].shape[0]\n",
    "    return max(dist_list)\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import cdist, euclidean\n",
    "\n",
    "def geometric_median_weinsfeild(X, eps=1e-5):\n",
    "    y = np.mean(X, 0)\n",
    "\n",
    "    while True:\n",
    "        D = cdist(X, [y])\n",
    "        nonzeros = (D != 0)[:, 0]\n",
    "\n",
    "        Dinv = 1 / D[nonzeros]\n",
    "        Dinvs = np.sum(Dinv)\n",
    "        W = Dinv / Dinvs\n",
    "        T = np.sum(W * X[nonzeros], 0)\n",
    "\n",
    "        num_zeros = len(X) - np.sum(nonzeros)\n",
    "        if num_zeros == 0:\n",
    "            y1 = T\n",
    "        elif num_zeros == len(X):\n",
    "            return y\n",
    "        else:\n",
    "            R = (T - y) * Dinvs\n",
    "            r = np.linalg.norm(R)\n",
    "            rinv = 0 if r == 0 else num_zeros/r\n",
    "            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n",
    "\n",
    "        if euclidean(y, y1) < eps:\n",
    "            return y1\n",
    "\n",
    "        y = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "empirical-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inter_cluster_distance(cluster_centroids) :\n",
    "    \n",
    "    number_of_clusters = cluster_centroids.shape[0]\n",
    "    intra_cluster_list = []\n",
    "    \n",
    "    for i in range(number_of_clusters) :\n",
    "        for j in range(i+1,number_of_clusters) :\n",
    "            eucl_dist = cluster_centroids[i] - cluster_centroids[j]\n",
    "            eucl_dist = np.square(eucl_dist)\n",
    "            eucl_dist = np.sum(eucl_dist)\n",
    "            eucl_dist = math.sqrt(eucl_dist)\n",
    "            \n",
    "            intra_cluster_list.append(eucl_dist)\n",
    "    \n",
    "    return min(intra_cluster_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "irish-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dunn_index(kmeans_object, trainData, givenLables = None) :\n",
    "    cluster_centroids = kmeans_object.cluster_centers_\n",
    "    if(givenLables is None):\n",
    "        train_data_labels = kmeans_object.labels_\n",
    "    else:\n",
    "        train_data_labels = givenLables\n",
    "    \n",
    "    #print(type(cluster_centroids))\n",
    "    #print(type(train_data_labels))\n",
    "    #print(cluster_centroids.shape)\n",
    "    #print(train_data_labels.shape)\n",
    "    #print(kmeans.inertia_)\n",
    "    \n",
    "    intra_cluster_dist = get_intra_cluster_distance(cluster_centroids,train_data_labels, trainData)\n",
    "    inter_cluster_dist = get_inter_cluster_distance(cluster_centroids)\n",
    "    \n",
    "    return inter_cluster_dist/intra_cluster_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "inappropriate-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(trainVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "center-cross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Index Accuracy of Train:0.781880\n",
      "Homogenity Score of Train 0.271935\n",
      "\n",
      "\n",
      "Rand Index Accuracy of Validation:0.781880\n",
      "Homogenity Score of Validation 0.271935\n",
      "\n",
      "\n",
      "Rand Index Accuracy of Test:0.780604\n",
      "Homogenity Score of Test 0.266596\n",
      "\n",
      "\n",
      "Dunn Index of the Cluster is :0.057186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import rand_score\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "\n",
    "pred = kmeans.predict(trainVector)\n",
    "score = rand_score(y_train,pred)\n",
    "print('Rand Index Accuracy of Train:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Train %.6f\" % homogeneity_score(y_train, pred))\n",
    "\n",
    "print()\n",
    "print()\n",
    "pred = kmeans.predict(validationVector)\n",
    "score = rand_score(y_validate,pred)\n",
    "print('Rand Index Accuracy of Validation:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Validation %.6f\" % homogeneity_score(y_validate, pred))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "pred = kmeans.predict(testVector)\n",
    "score = rand_score(y_test,pred)\n",
    "print('Rand Index Accuracy of Test:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Test %.6f\" % homogeneity_score(y_test, pred))\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Dunn Index of the Cluster is :{0:f}'.format(return_dunn_index(kmeans, trainVector)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "conventional-weekly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(trainVector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "governing-beginning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.972000\n"
     ]
    }
   ],
   "source": [
    "svmPredtrain = clf.predict(trainVector)\n",
    "score = accuracy_score(y_train,svmPredtrain)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "collect-category",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Validate:0.972000\n",
      "Accuracy Test:0.960667\n"
     ]
    }
   ],
   "source": [
    "svmPredvalidate = clf.predict(validationVector)\n",
    "score = accuracy_score(y_validate,svmPredvalidate)\n",
    "print('Accuracy Validate:{0:f}'.format(score))\n",
    "\n",
    "svmPredtest = clf.predict(testVector)\n",
    "score = accuracy_score(y_test,svmPredtest)\n",
    "print('Accuracy Test:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "hispanic-center",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn Index of the Cluster is :0.057186\n"
     ]
    }
   ],
   "source": [
    "print('Dunn Index of the Cluster is :{0:f}'.format(return_dunn_index(kmeans, trainVector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alike-flavor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 10)\n",
      "(250, 10)\n",
      "(250, 10)\n"
     ]
    }
   ],
   "source": [
    "print(testVector.shape)\n",
    "print(validationVector.shape)\n",
    "print(trainVector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fewer-albert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 69.34128354, 510.22491515, 336.46999172, 343.71676551,\n",
       "       234.77264256, 353.8099154 , 242.16562397, 165.87642801,\n",
       "       289.06716178, 147.81402484])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometric_median_weinsfeild(trainVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-gambling",
   "metadata": {},
   "source": [
    "# Generalized Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "approximate-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphHelperGM:\n",
    "    def __init__(self, trainData):\n",
    "        self.trainData = trainData\n",
    "        \n",
    "    def GraphToVector(self,graphSet):\n",
    "        ged_env = GEDEnv() # initailize GED environment.\n",
    "        ged_env.set_edit_cost('CONSTANT', # GED cost type.\n",
    "                            edit_cost_constants=[3, 3, 1, 3, 3, 1] # edit costs.\n",
    "                            )  \n",
    "        for graph in graphSet:\n",
    "            ged_env.add_nx_graph(graph, '') # add graph1\n",
    "        for graph in self.trainData:\n",
    "            ged_env.add_nx_graph(graph, '') # add graph1\n",
    "        listID = ged_env.get_all_graph_ids() # get list IDs of graphs\n",
    "        ged_env.init(init_type='LAZY_WITHOUT_SHUFFLED_COPIES') # initialize GED environment.\n",
    "        options = {'initialization_method': 'RANDOM', # or 'NODE', etc.\n",
    "                'threads': 1 # parallel threads.\n",
    "                }\n",
    "        ged_env.set_method('BIPARTITE', # GED method.\n",
    "                        options # options for GED method.\n",
    "                        )\n",
    "        ged_env.init_method() # initialize GED method.\n",
    "        \n",
    "        \n",
    "        vectorMatrix = np.empty(shape= (len(graphSet), len(self.trainData)))\n",
    "        for row, graph in enumerate(graphSet):\n",
    "            for col  in range(len(self.trainData)):\n",
    "                ged_env.run_method(listID[row], listID[len(graphSet) + col]) # run.\n",
    "                dis = ged_env.get_upper_bound(listID[row], listID[len(graphSet) + col])\n",
    "                vectorMatrix[row][col] = dis\n",
    "        return vectorMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "involved-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphGM = GraphHelperGM(XtrainAids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "vietnamese-burns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1448.453125\n",
      "Completed Test at  2021-04-27 16:23:26.291111\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "trainVectorGM = graphGM.GraphToVector(XtrainAids)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Test at \", str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "corporate-football",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9167.9375\n",
      "Completed Test at  2021-04-27 19:11:36.378615\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "testVectorGM = graphGM.GraphToVector(XtestAids)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Test at \", str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "healthy-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1479.140625\n",
      "Completed Test at  2021-04-27 19:36:36.678905\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "validationVectorGM = graphGM.GraphToVector(XvalidateAids)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Test at \", str(now))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-valentine",
   "metadata": {},
   "source": [
    "## Saving Data Grec GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "annoying-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"TrainVectorGRECGM\", trainVectorGM)\n",
    "np.save(\"TestVectorGRECGM\", testVectorGM)\n",
    "np.save(\"validateVectorGRECGM\", validationVectorGM)\n",
    "with open('GraphHelperObjGRECGM', 'wb') as config_dictionary_file:\n",
    "    pickle.dump(graphGM, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-spotlight",
   "metadata": {},
   "source": [
    "## Loading Data Grec GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "minute-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVectorGM = np.load(\"TrainVectorGRECGM.npy\")\n",
    "testVectorGM = np.load(\"TestVectorGRECGM.npy\")\n",
    "validationVectorGM = np.load(\"validateVectorGRECGM.npy\")\n",
    "with open('GraphHelperObjGRECGM', 'rb') as config_dictionary_file:\n",
    "    graphGM = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "healthy-architecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Index Accuracy of Train:0.825735\n",
      "Homogenity Score of Train 0.390315\n",
      "\n",
      "\n",
      "Rand Index Accuracy of Validation:0.825735\n",
      "Homogenity Score of Validation 0.390315\n",
      "\n",
      "\n",
      "Rand Index Accuracy of Test:0.829558\n",
      "Homogenity Score of Test 0.399280\n",
      "\n",
      "\n",
      "Dunn Index of the Cluster is :3.175717\n",
      "Dunn Index of Ground Truth is : 0.969642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import rand_score\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "\n",
    "\n",
    "kmeansGM = KMeans(n_clusters=2, random_state=0).fit(trainVectorGM)\n",
    "pred = kmeansGM.predict(trainVectorGM)\n",
    "score = rand_score(y_train,pred)\n",
    "print('Rand Index Accuracy of Train:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Train %.6f\" % homogeneity_score(y_train, pred))\n",
    "\n",
    "print()\n",
    "print()\n",
    "pred = kmeansGM.predict(validationVectorGM)\n",
    "score = rand_score(y_validate,pred)\n",
    "print('Rand Index Accuracy of Validation:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Validation %.6f\" % homogeneity_score(y_validate, pred))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "pred = kmeansGM.predict(testVectorGM)\n",
    "score = rand_score(y_test,pred)\n",
    "print('Rand Index Accuracy of Test:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Test %.6f\" % homogeneity_score(y_test, pred))\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Dunn Index of the Cluster is :{0:f}'.format(return_dunn_index(kmeansGM, trainVectorGM)))\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_labels = le.fit_transform(y_train)\n",
    "print(\"Dunn Index of Ground Truth is : {0:f}\".format(return_dunn_index(kmeansGM, trainVectorGM, y_train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "furnished-worker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "minor-tactics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-battle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
