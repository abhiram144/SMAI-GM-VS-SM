{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brown-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import sys\n",
    "from graphkitlearn.graphkitlearn.gklearn.utils import graphfiles\n",
    "import networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gklearn.utils import *\n",
    "import os\n",
    "import random\n",
    "from gklearn.ged.env import GEDEnv\n",
    "import numpy as np\n",
    "from time import process_time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import *\n",
    "import datetime\n",
    "pathGrec = \"./GREC/GREC/data/\"\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "military-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(filename, childrentagName):\n",
    "    import xml.etree.ElementTree as ET\n",
    "    dirname_dataset = os.path.dirname(filename)\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    data = []\n",
    "    y = []\n",
    "    children = list([elem for elem in root.find(childrentagName).iter() if elem is not root.find(childrentagName)])\n",
    "    for graph in children:\n",
    "        mol_filename = graph.attrib['file']\n",
    "        mol_class = graph.attrib['class']\n",
    "        data.append(graphfiles.loadGXL(dirname_dataset + '/' + mol_filename))\n",
    "        y.append(mol_class)\n",
    "    return data, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vertical-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphHelper:\n",
    "    def __init__(self, trainData, mProtoTypes):\n",
    "        self.trainData = trainData\n",
    "        self.InitializeGraphToVector(trainData, mProtoTypes)\n",
    "        self.mProtoTypes = mProtoTypes\n",
    "        \n",
    "    def GetDistanceBetweenGraphs(self,graph1, graph2):\n",
    "        ged_env = GEDEnv() # initailize GED environment.\n",
    "        ged_env.set_edit_cost('CONSTANT', # GED cost type.\n",
    "                            edit_cost_constants=[3, 3, 1, 3, 3, 1] # edit costs.\n",
    "                            )  \n",
    "        ged_env.add_nx_graph(graph1, '') # add graph1\n",
    "        ged_env.add_nx_graph(graph2, '') # add graph2\n",
    "        listID = ged_env.get_all_graph_ids() # get list IDs of graphs\n",
    "        ged_env.init(init_type='LAZY_WITHOUT_SHUFFLED_COPIES') # initialize GED environment.\n",
    "        options = {'initialization_method': 'RANDOM', # or 'NODE', etc.\n",
    "                'threads': 1 # parallel threads.\n",
    "                }\n",
    "        ged_env.set_method('BIPARTITE', # GED method.\n",
    "                        options # options for GED method.\n",
    "                        )\n",
    "        ged_env.init_method() # initialize GED method.\n",
    "\n",
    "        ged_env.run_method(listID[0], listID[1]) # run.\n",
    "        dis = ged_env.get_upper_bound(listID[0], listID[1])\n",
    "        return dis\n",
    "\n",
    "    def MaxEditDistance(self, graphSets, nodes, addedIndices):\n",
    "        distanceVector = np.empty(shape=(len(graphSets ), len(nodes)))\n",
    "        for graphIndex,graph in enumerate(graphSets):\n",
    "            for nodeIndex,node in enumerate(nodes):\n",
    "                dis = self.GetDistanceBetweenGraphs(graph, node)\n",
    "                distanceVector[graphIndex][nodeIndex] = dis\n",
    "        maxValue = -1\n",
    "        maxIndex = -1\n",
    "        for graphIndex in range(len(graphSets)):\n",
    "            if(graphIndex not in addedIndices):\n",
    "                maxDistanceIndex = np.argmax(distanceVector[graphIndex])\n",
    "                if(distanceVector[graphIndex][maxDistanceIndex] > maxValue):\n",
    "                    maxValue = distanceVector[graphIndex][maxDistanceIndex]\n",
    "                    maxIndex = graphIndex\n",
    "\n",
    "        return maxIndex\n",
    "\n",
    "    def SelectSpanningPrototypes(self, graphData, mprototypes):\n",
    "        choiceIndex = random.randrange(len(graphData))\n",
    "        graphSelected = [graphData[choiceIndex]]\n",
    "        graphSelectedIndex = [choiceIndex]\n",
    "\n",
    "        for selectors in range(mprototypes - 1):\n",
    "            maxEditDistanceIndex = self.MaxEditDistance(graphData, graphSelected, graphSelectedIndex)\n",
    "            graphSelectedIndex.append(maxEditDistanceIndex)\n",
    "            graphSelected.append(graphData[maxEditDistanceIndex])\n",
    "        return graphSelectedIndex\n",
    "    \n",
    "    def GraphToVector(self, graphSet):\n",
    "        vectorMatrix = np.empty(shape= (len(graphSet), self.mProtoTypes))\n",
    "        for row, graph in enumerate(graphSet):\n",
    "            for col,prototypeIndex in enumerate(self.selectedProtoTypes):\n",
    "                vectorMatrix[row][col] = self.GetDistanceBetweenGraphs(graph, self.trainData[prototypeIndex])\n",
    "        return vectorMatrix\n",
    "    \n",
    "    def InitializeGraphToVector(self, graphSet, mprotoTypes):\n",
    "        self.selectedProtoTypes = self.SelectSpanningPrototypes(graphSet, mprotoTypes)\n",
    "        #return self.GraphToVector(graphSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "matched-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainGREC, y_train = LoadData(pathGrec +\"train.cxl\", \"grec\")\n",
    "XvalidateGREC, y_validate = LoadData(pathGrec +\"valid.cxl\", \"grec\")\n",
    "XtestGREC, y_test = LoadData(pathGrec +\"test.cxl\", \"grec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dental-still",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290.578125\n",
      "Completed Prototype Selection at  2021-04-24 15:59:14.563900\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "graph = GraphHelper(XtrainGREC, 10)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Prototype Selection at \", str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hungarian-series",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.34375\n",
      "Completed Train Conversion at  2021-04-24 16:00:24.274217\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "trainVector = graph.GraphToVector(XtrainGREC)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Train Conversion at \", str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amino-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.28125\n",
      "Completed Test at  2021-04-24 16:02:44.848174\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "testVector = graph.GraphToVector(XtestGREC)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Test at \", str(now))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southwest-pillow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.359375\n",
      "Completed Validation at  2021-04-24 16:03:53.524782\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "validationVector = graph.GraphToVector(XvalidateGREC)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Validation at \", str(now))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-assurance",
   "metadata": {},
   "source": [
    "## Saving the computed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "electoral-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"TrainVectorGREC\", trainVector)\n",
    "np.save(\"TestVectorGREC\", testVector)\n",
    "np.save(\"validateVectorGREC\", validationVector)\n",
    "with open('GraphHelperObjGREC', 'wb') as config_dictionary_file:\n",
    "    pickle.dump(graph, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-france",
   "metadata": {},
   "source": [
    "## Loading from saved files \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "false-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVector = np.load(\"TrainVectorGREC.npy\")\n",
    "testVector = np.load(\"TestVectorGREC.npy\")\n",
    "validationVector = np.load(\"validateVectorGREC.npy\")\n",
    "with open('GraphHelperObjGREC', 'rb') as config_dictionary_file:\n",
    "    graph = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "italic-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def delta_fast(ck, cl, distances):\n",
    "    values = distances[np.where(ck)][:, np.where(cl)]\n",
    "    values = values[np.nonzero(values)]\n",
    "\n",
    "    return np.min(values)\n",
    "    \n",
    "def big_delta_fast(ci, distances):\n",
    "    values = distances[np.where(ci)][:, np.where(ci)]\n",
    "    #values = values[np.nonzero(values)]\n",
    "            \n",
    "    return np.max(values)\n",
    "\n",
    "def dunn_fast(points, labels):\n",
    "    \"\"\" Dunn index - FAST (using sklearn pairwise euclidean_distance function)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    points : np.array\n",
    "        np.array([N, p]) of all points\n",
    "    labels: np.array\n",
    "        np.array([N]) labels of all points\n",
    "    \"\"\"\n",
    "    distances = euclidean_distances(points)\n",
    "    ks = np.sort(np.unique(labels))\n",
    "    \n",
    "    deltas = np.ones([len(ks), len(ks)])*1000000\n",
    "    big_deltas = np.zeros([len(ks), 1])\n",
    "    \n",
    "    l_range = list(range(0, len(ks)))\n",
    "    \n",
    "    for k in l_range:\n",
    "        for l in (l_range[0:k]+l_range[k+1:]):\n",
    "            deltas[k, l] = delta_fast((labels == ks[k]), (labels == ks[l]), distances)\n",
    "        \n",
    "        big_deltas[k] = big_delta_fast((labels == ks[k]), distances)\n",
    "\n",
    "    di = np.min(deltas)/np.max(big_deltas)\n",
    "    return di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "inappropriate-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=22, random_state=0).fit(trainVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "center-cross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Index Accuracy of Train:0.874985\n",
      "Homogenity Score of Train 0.421175\n",
      "Dunn Index of the Cluster is :0.100028\n",
      "Dunn Index of the Ground Truth is :0.028285\n",
      "\n",
      "\n",
      "Rand Index Accuracy of Validation:0.866544\n",
      "Homogenity Score of Validation 0.408794\n",
      "Dunn Index of the Cluster is :0.080831\n",
      "Dunn Index of the Ground Truth is :0.033777\n",
      "\n",
      "\n",
      "Rand Index Accuracy of Test:0.867661\n",
      "Homogenity Score of Test 0.379925\n",
      "Dunn Index of the Cluster is :0.071990\n",
      "Dunn Index of the Ground Truth is :0.031561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import rand_score\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "\n",
    "pred = kmeans.predict(trainVector)\n",
    "score = rand_score(y_train,pred)\n",
    "print('Rand Index Accuracy of Train:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Train %.6f\" % homogeneity_score(y_train, pred))\n",
    "print('Dunn Index of the Cluster is :{0:f}'.format(dunn_fast(trainVector, pred)))\n",
    "le = LabelEncoder()\n",
    "y_train_labels = le.fit_transform(y_train)\n",
    "print('Dunn Index of the Ground Truth is :{0:f}'.format(dunn_fast(trainVector, y_train_labels)))\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "pred = kmeans.predict(validationVector)\n",
    "score = rand_score(y_validate,pred)\n",
    "print('Rand Index Accuracy of Validation:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Validation %.6f\" % homogeneity_score(y_validate, pred))\n",
    "print('Dunn Index of the Cluster is :{0:f}'.format(dunn_fast(validationVector, pred)))\n",
    "le = LabelEncoder()\n",
    "y_validate_labels = le.fit_transform(y_validate)\n",
    "print('Dunn Index of the Ground Truth is :{0:f}'.format(dunn_fast(validationVector, y_validate_labels)))\n",
    "\n",
    "print()\n",
    "print()\n",
    "pred = kmeans.predict(testVector)\n",
    "score = rand_score(y_test,pred)\n",
    "print('Rand Index Accuracy of Test:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Test %.6f\" % homogeneity_score(y_test, pred))\n",
    "print('Dunn Index of the Cluster is :{0:f}'.format(dunn_fast(testVector, pred)))\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_labels = le.fit_transform(y_test)\n",
    "print('Dunn Index of the Ground Truth is :{0:f}'.format(dunn_fast(testVector, y_train_labels)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-evans",
   "metadata": {},
   "source": [
    "# Generalized Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "temporal-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphHelperGM:\n",
    "    def __init__(self, trainData):\n",
    "        self.trainData = trainData\n",
    "        \n",
    "    def GraphToVector(self,graphSet):\n",
    "        ged_env = GEDEnv() # initailize GED environment.\n",
    "        ged_env.set_edit_cost('CONSTANT', # GED cost type.\n",
    "                            edit_cost_constants=[3, 3, 1, 3, 3, 1] # edit costs.\n",
    "                            )  \n",
    "        for graph in graphSet:\n",
    "            ged_env.add_nx_graph(graph, '') # add graph1\n",
    "        for graph in self.trainData:\n",
    "            ged_env.add_nx_graph(graph, '') # add graph1\n",
    "        listID = ged_env.get_all_graph_ids() # get list IDs of graphs\n",
    "        ged_env.init(init_type='LAZY_WITHOUT_SHUFFLED_COPIES') # initialize GED environment.\n",
    "        options = {'initialization_method': 'RANDOM', # or 'NODE', etc.\n",
    "                'threads': 1 # parallel threads.\n",
    "                }\n",
    "        ged_env.set_method('BIPARTITE', # GED method.\n",
    "                        options # options for GED method.\n",
    "                        )\n",
    "        ged_env.init_method() # initialize GED method.\n",
    "        \n",
    "        \n",
    "        vectorMatrix = np.empty(shape= (len(graphSet), len(self.trainData)))\n",
    "        for row, graph in enumerate(graphSet):\n",
    "            for col  in range(len(self.trainData)):\n",
    "                ged_env.run_method(listID[row], listID[len(graphSet) + col]) # run.\n",
    "                dis = ged_env.get_upper_bound(listID[row], listID[len(graphSet) + col])\n",
    "                vectorMatrix[row][col] = dis\n",
    "        return vectorMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "treated-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphGM = GraphHelperGM(XtrainGREC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "extraordinary-mississippi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312.765625\n",
      "Completed Test at  2021-04-27 12:13:35.509919\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "trainVectorGM = graphGM.GraphToVector(XtrainGREC)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Test at \", str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "functional-dynamics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261.484375\n",
      "Completed Test at  2021-04-27 12:54:40.666656\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "testVectorGM = graphGM.GraphToVector(XtestGREC)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Test at \", str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "beautiful-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963.75\n",
      "Completed Test at  2021-04-27 13:10:45.252495\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "validationVectorGM = graphGM.GraphToVector(XvalidateGREC)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Test at \", str(now))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-actor",
   "metadata": {},
   "source": [
    "## Saving Data Grec GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "straight-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"TrainVectorGRECGM\", trainVectorGM)\n",
    "np.save(\"TestVectorGRECGM\", testVectorGM)\n",
    "np.save(\"validateVectorGRECGM\", validationVectorGM)\n",
    "with open('GraphHelperObjGRECGM', 'wb') as config_dictionary_file:\n",
    "    pickle.dump(graphGM, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-arrangement",
   "metadata": {},
   "source": [
    "## Loading Data Grec GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fossil-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVectorGM = np.load(\"TrainVectorGRECGM.npy\")\n",
    "testVectorGM = np.load(\"TestVectorGRECGM.npy\")\n",
    "validationVectorGM = np.load(\"validateVectorGRECGM.npy\")\n",
    "with open('GraphHelperObjGRECGM', 'rb') as config_dictionary_file:\n",
    "    graphGM = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "positive-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Index Accuracy of Train:0.906760\n",
      "Homogenity Score of Train 0.549132\n",
      "\n",
      "\n",
      "Rand Index Accuracy of Validation:0.901264\n",
      "Homogenity Score of Validation 0.531163\n",
      "\n",
      "\n",
      "Rand Index Accuracy of Test:0.904620\n",
      "Homogenity Score of Test 0.525437\n",
      "\n",
      "\n",
      "Dunn Index of the Cluster is :0.614202\n",
      "Dunn Index of Ground Truth is : 0.067274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import rand_score\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "kmeansGM = KMeans(n_clusters=22, random_state=0).fit(trainVectorGM)\n",
    "pred = kmeansGM.predict(trainVectorGM)\n",
    "score = rand_score(y_train,pred)\n",
    "print('Rand Index Accuracy of Train:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Train %.6f\" % homogeneity_score(y_train, pred))\n",
    "\n",
    "print()\n",
    "print()\n",
    "pred = kmeansGM.predict(validationVectorGM)\n",
    "score = rand_score(y_validate,pred)\n",
    "print('Rand Index Accuracy of Validation:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Validation %.6f\" % homogeneity_score(y_validate, pred))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "pred = kmeansGM.predict(testVectorGM)\n",
    "score = rand_score(y_test,pred)\n",
    "print('Rand Index Accuracy of Test:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Test %.6f\" % homogeneity_score(y_test, pred))\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Dunn Index of the Cluster is :{0:f}'.format(return_dunn_index(kmeansGM, trainVectorGM)))\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_labels = le.fit_transform(y_train)\n",
    "print(\"Dunn Index of Ground Truth is : {0:f}\".format(return_dunn_index(kmeansGM, trainVectorGM, y_train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-mouse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
