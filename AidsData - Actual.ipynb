{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brown-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import sys\n",
    "from graphkitlearn.graphkitlearn.gklearn.utils import graphfiles\n",
    "import networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gklearn.utils import *\n",
    "import os\n",
    "import random\n",
    "from gklearn.ged.env import GEDEnv\n",
    "import numpy as np\n",
    "from time import process_time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import *\n",
    "import datetime\n",
    "pathAids = \"./AIDS/AIDS/data/\"\n",
    "path1Grec = \"./GREC/GREC/data/\"\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "military-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(filename, childrentagName):\n",
    "    import xml.etree.ElementTree as ET\n",
    "    dirname_dataset = os.path.dirname(filename)\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    data = []\n",
    "    y = []\n",
    "    children = list([elem for elem in root.find(childrentagName).iter() if elem is not root.find(childrentagName)])\n",
    "    for graph in children:\n",
    "        mol_filename = graph.attrib['file']\n",
    "        mol_class = graph.attrib['class']\n",
    "        data.append(graphfiles.loadGXL(dirname_dataset + '/' + mol_filename))\n",
    "        y.append(mol_class)\n",
    "    return data, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vertical-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphHelper:\n",
    "    def __init__(self, trainData, mProtoTypes):\n",
    "        self.trainData = trainData\n",
    "        self.InitializeGraphToVector(trainData, mProtoTypes)\n",
    "        self.mProtoTypes = mProtoTypes\n",
    "        \n",
    "    def GetDistanceBetweenGraphs(self,graph1, graph2):\n",
    "        ged_env = GEDEnv() # initailize GED environment.\n",
    "        ged_env.set_edit_cost('CONSTANT', # GED cost type.\n",
    "                            edit_cost_constants=[3, 3, 1, 3, 3, 1] # edit costs.\n",
    "                            )  \n",
    "        ged_env.add_nx_graph(graph1, '') # add graph1\n",
    "        ged_env.add_nx_graph(graph2, '') # add graph2\n",
    "        listID = ged_env.get_all_graph_ids() # get list IDs of graphs\n",
    "        ged_env.init(init_type='LAZY_WITHOUT_SHUFFLED_COPIES') # initialize GED environment.\n",
    "        options = {'initialization_method': 'RANDOM', # or 'NODE', etc.\n",
    "                'threads': 1 # parallel threads.\n",
    "                }\n",
    "        ged_env.set_method('BIPARTITE', # GED method.\n",
    "                        options # options for GED method.\n",
    "                        )\n",
    "        ged_env.init_method() # initialize GED method.\n",
    "\n",
    "        ged_env.run_method(listID[0], listID[1]) # run.\n",
    "        dis = ged_env.get_upper_bound(listID[0], listID[1])\n",
    "        return dis\n",
    "\n",
    "    def MaxEditDistance(self, graphSets, nodes, addedIndices):\n",
    "        distanceVector = np.empty(shape=(len(graphSets ), len(nodes)))\n",
    "        for graphIndex,graph in enumerate(graphSets):\n",
    "            for nodeIndex,node in enumerate(nodes):\n",
    "                dis = self.GetDistanceBetweenGraphs(graph, node)\n",
    "                distanceVector[graphIndex][nodeIndex] = dis\n",
    "        maxValue = -1\n",
    "        maxIndex = -1\n",
    "        for graphIndex in range(len(graphSets)):\n",
    "            if(graphIndex not in addedIndices):\n",
    "                maxDistanceIndex = np.argmax(distanceVector[graphIndex])\n",
    "                if(distanceVector[graphIndex][maxDistanceIndex] > maxValue):\n",
    "                    maxValue = distanceVector[graphIndex][maxDistanceIndex]\n",
    "                    maxIndex = graphIndex\n",
    "\n",
    "        return maxIndex\n",
    "\n",
    "    def SelectSpanningPrototypes(self, graphData, mprototypes):\n",
    "        choiceIndex = random.randrange(len(graphData))\n",
    "        graphSelected = [graphData[choiceIndex]]\n",
    "        graphSelectedIndex = [choiceIndex]\n",
    "\n",
    "        for selectors in range(mprototypes - 1):\n",
    "            maxEditDistanceIndex = self.MaxEditDistance(graphData, graphSelected, graphSelectedIndex)\n",
    "            graphSelectedIndex.append(maxEditDistanceIndex)\n",
    "            graphSelected.append(graphData[maxEditDistanceIndex])\n",
    "        return graphSelectedIndex\n",
    "    \n",
    "    def GraphToVector(self, graphSet):\n",
    "        vectorMatrix = np.empty(shape= (len(graphSet), self.mProtoTypes))\n",
    "        for row, graph in enumerate(graphSet):\n",
    "            for col,prototypeIndex in enumerate(self.selectedProtoTypes):\n",
    "                vectorMatrix[row][col] = self.GetDistanceBetweenGraphs(graph, self.trainData[prototypeIndex])\n",
    "        return vectorMatrix\n",
    "    \n",
    "    def InitializeGraphToVector(self, graphSet, mprotoTypes):\n",
    "        self.selectedProtoTypes = self.SelectSpanningPrototypes(graphSet, mprotoTypes)\n",
    "        #return self.GraphToVector(graphSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "matched-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainAids, y_train = LoadData(pathAids +\"train.cxl\", \"fingerprints\")\n",
    "XvalidateAids, y_validate = LoadData(pathAids +\"valid.cxl\", \"fingerprints\")\n",
    "XtestAids, y_test = LoadData(pathAids +\"test.cxl\", \"fingerprints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dental-still",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853.046875\n",
      "Completed Prototype Selection at  2021-04-24 13:18:20.758335\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "graph = GraphHelper(XtrainAids, 10)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Prototype Selection at \", str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hungarian-series",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171.171875\n",
      "Completed Train Conversion at  2021-04-24 13:21:13.061440\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "trainVector = graph.GraphToVector(XtrainAids)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Train Conversion at \", str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amino-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034.9375\n",
      "Completed Test at  2021-04-24 13:38:34.677509\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "testVector = graph.GraphToVector(XtestAids)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Test at \", str(now))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southwest-pillow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.8125\n",
      "Completed Validation at  2021-04-24 13:41:28.737996\n"
     ]
    }
   ],
   "source": [
    "t1_start = process_time() \n",
    "validationVector = graph.GraphToVector(XvalidateAids)\n",
    "t1_stop = process_time()\n",
    "print(t1_stop - t1_start)\n",
    "now = datetime.datetime.now()\n",
    "print(\"Completed Validation at \", str(now))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-assurance",
   "metadata": {},
   "source": [
    "## Saving the computed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "electoral-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"TrainVectorAids\", trainVector)\n",
    "np.save(\"TestVectorAids\", testVector)\n",
    "np.save(\"validateVectorAids\", validationVector)\n",
    "with open('GraphHelperObjAids', 'wb') as config_dictionary_file:\n",
    "    pickle.dump(graph, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-france",
   "metadata": {},
   "source": [
    "## Loading from saved files \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "false-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainVector = np.load(\"TrainVectorAids.npy\")\n",
    "testVector = np.load(\"TestVectorAids.npy\")\n",
    "validationVector = np.load(\"validateVectorAids.npy\")\n",
    "with open('GraphHelperObjAids', 'rb') as config_dictionary_file:\n",
    "    graph = pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inappropriate-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(trainVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "center-cross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn Index Accuracy of Train:0.781880\n",
      "Homogenity Score of Train 0.271935\n",
      "\n",
      "\n",
      "Dunn Index Accuracy of Validation:0.781880\n",
      "Homogenity Score of Validation 0.271935\n",
      "\n",
      "\n",
      "Dunn Index Accuracy of Test:0.780604\n",
      "Homogenity Score of Test 0.266596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import rand_score\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "\n",
    "pred = kmeans.predict(trainVector)\n",
    "score = rand_score(y_train,pred)\n",
    "print('Dunn Index Accuracy of Train:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Train %.6f\" % homogeneity_score(y_train, pred))\n",
    "\n",
    "print()\n",
    "print()\n",
    "pred = kmeans.predict(validationVector)\n",
    "score = rand_score(y_validate,pred)\n",
    "print('Dunn Index Accuracy of Validation:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Validation %.6f\" % homogeneity_score(y_validate, pred))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "pred = kmeans.predict(testVector)\n",
    "score = rand_score(y_test,pred)\n",
    "print('Dunn Index Accuracy of Test:{0:f}'.format(score))\n",
    "print(\"Homogenity Score of Test %.6f\" % homogeneity_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "conventional-weekly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(trainVector, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "governing-beginning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.972000\n"
     ]
    }
   ],
   "source": [
    "svmPredtrain = clf.predict(trainVector)\n",
    "score = accuracy_score(y_train,svmPredtrain)\n",
    "print('Accuracy:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "collect-category",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Validate:0.972000\n",
      "Accuracy Test:0.960667\n"
     ]
    }
   ],
   "source": [
    "svmPredvalidate = clf.predict(validationVector)\n",
    "score = accuracy_score(y_validate,svmPredvalidate)\n",
    "print('Accuracy Validate:{0:f}'.format(score))\n",
    "\n",
    "svmPredtest = clf.predict(testVector)\n",
    "score = accuracy_score(y_test,svmPredtest)\n",
    "print('Accuracy Test:{0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alike-flavor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 10)\n",
      "(250, 10)\n",
      "(250, 10)\n"
     ]
    }
   ],
   "source": [
    "print(testVector.shape)\n",
    "print(validationVector.shape)\n",
    "print(trainVector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-albert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
